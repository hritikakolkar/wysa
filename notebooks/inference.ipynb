{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "from src.models.Classifier import EmotionClassifier\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference():\n",
    "    def __init__(self, model_path, model_name, pretrained_model_path = \"../weights/twitter-roberta-base-sentiment-latest\", max_length= 70):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "        self.model = EmotionClassifier(num_classes_emotion=3, pretrained_model_path= pretrained_model_path)\n",
    "        self.model.load_state_dict(torch.load(os.path.join(model_path, model_name)))\n",
    "        self.model.to(self.device)\n",
    "        self.max_length = max_length\n",
    "        self.id_to_emotion = ['No emotion toward brand or product', 'Positive emotion', 'Negative emotion']\n",
    "\n",
    "    def get_batch_inference(self, batch_tweets: List)-> List:\n",
    "        batch = self.tokenizer(batch_tweets, padding=True, truncation=True, max_length = 70, return_tensors=\"pt\")\n",
    "        batch.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(**batch)\n",
    "        return list(map(lambda x: self.id_to_emotion[x], torch.argmax(output, dim=1).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Results for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.utils import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../weights/v001\"\n",
    "model_name = \"pytorch_model.bin\"\n",
    "inference = Inference(model_path= model_path, model_name= model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = pd.read_excel(\"../data/dataset.xlsx\", sheet_name = \"Test\")\n",
    "test = preprocessing(original_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to do batch as this is only one time but I did it\n",
    "batch_size = 16\n",
    "tweets = test[\"tweet\"].tolist()\n",
    "emotion_list = []\n",
    "for i in range(0, len(tweets), batch_size):\n",
    "    emotion_list.extend(inference.get_batch_inference(tweets[i:i+batch_size]))\n",
    "original_test[\"emotion\"] = emotion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test.to_excel(\"../data/result.xlsx\", sheet_name= \"Test\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
